{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Rohlik2 Lama v6 weighted](https://www.kaggle.com/code/samvelkoch/rohlik2-lama-v6-weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import torch\n",
    "\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 12\n",
    "N_FOLDS = 8\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TIMEOUT = 3600*100\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/sales_train.csv', parse_dates= ['date'])\n",
    "test = pd.read_csv('../../data/sales_test.csv', parse_dates= ['date']  )\n",
    "ss = pd.read_csv('../../data/solution.csv')\n",
    "inventory = pd.read_csv('../../data/inventory.csv')\n",
    "weights  = pd.read_csv('../../data/test_weights.csv')\n",
    "calendar  = pd.read_csv('../../data/calendar.csv', parse_dates= ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frankfurt_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Frankfurt_1\"')\n",
    "Prague_2 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_2\"')\n",
    "Brno_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Brno_1\"')\n",
    "Munich_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Munich_1\"')\n",
    "Prague_3 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_3\"')\n",
    "Prague_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_1\"')\n",
    "Budapest_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Budapest_1\"')\n",
    "\n",
    "def process_calendar(df):\n",
    "    \"\"\"\n",
    "    Обрабатывает календарный датафрейм, добавляя новые колонки:\n",
    "    - days_to_holiday\n",
    "    - days_to_shops_closed\n",
    "    - day_after_closing\n",
    "    - long_weekend\n",
    "    - weekday\n",
    "    \"\"\"\n",
    "    # Убеждаемся, что даты отсортированы\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # 1. days_to_holiday\n",
    "    df['next_holiday_date'] = df.loc[df['holiday'] == 1, 'date'].shift(-1)\n",
    "    df['next_holiday_date'] = df['next_holiday_date'].bfill()\n",
    "    df['days_to_holiday'] = (df['next_holiday_date'] - df['date']).dt.days\n",
    "    df.drop(columns=['next_holiday_date'], inplace=True)\n",
    "    \n",
    "    # 2. days_to_shops_closed\n",
    "    df['next_shops_closed_date'] = df.loc[df['shops_closed'] == 1, 'date'].shift(-1)\n",
    "    df['next_shops_closed_date'] = df['next_shops_closed_date'].bfill()\n",
    "    df['days_to_shops_closed'] = (df['next_shops_closed_date'] - df['date']).dt.days\n",
    "    df.drop(columns=['next_shops_closed_date'], inplace=True)\n",
    "    \n",
    "    # 3. day_after_closing\n",
    "    df['day_after_closing'] = (\n",
    "        (df['shops_closed'] == 0) & (df['shops_closed'].shift(1) == 1)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 4. long_weekend\n",
    "    df['long_weekend'] = (\n",
    "        (df['shops_closed'] == 1) & (df['shops_closed'].shift(1) == 1)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 5. weekday\n",
    "    df['weekday'] = df['date'].dt.weekday  # 0 (понедельник) - 6 (воскресенье)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Список датафреймов\n",
    "dfs = ['Frankfurt_1', 'Prague_2', 'Brno_1', 'Munich_1', 'Prague_3', 'Prague_1', 'Budapest_1']\n",
    "\n",
    "# Применяем функцию ко всем датафреймам и собираем их в список\n",
    "processed_dfs = [process_calendar(globals()[df]) for df in dfs]\n",
    "\n",
    "# Конкатенируем все датафреймы в один\n",
    "calendar_extended = pd.concat(processed_dfs).sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_calendar = train.merge(calendar_extended, on=['date', 'warehouse'], how='left')\n",
    "train_inventory = train_calendar.merge(inventory, on=['unique_id', 'warehouse'], how='left')\n",
    "train_data = train_inventory.merge(weights, on=['unique_id'], how='left')\n",
    "\n",
    "test_calendar = test.merge(calendar_extended, on=['date', 'warehouse'], how='left')\n",
    "test_data = test_calendar.merge(inventory, on=['unique_id', 'warehouse'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['availability'])\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(subset=['sales'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sort_values(['unique_id', 'date'])\n",
    "#train_data = train_data.set_index('date')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "automl = TabularAutoML(\n",
    "    task = task,\n",
    "    # timeout = TIMEOUT,\n",
    "    cpu_limit = N_THREADS,\n",
    "    #general_params = {'use_algos':[['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "    selection_params={'mode' : 0},\n",
    "    tuning_params = {'max_tuning_time': 3600},\n",
    "    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    ")\n",
    "\n",
    "out_of_fold_predictions = automl.fit_predict(\n",
    "    train_data,\n",
    "    roles = {\n",
    "        'target': 'sales',\n",
    "        #'drop': ['unique_id']\n",
    "        'weights': 'weight'\n",
    "    }, \n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(automl, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = automl.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': ss.id.values,\n",
    "    'sales_hat': test_predictions.data[:, 0],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lama_v6_weighted.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAE score: {mean_absolute_error(train_data[\"sales\"].values, submission[\"sales_hat\"].values)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
